{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Multiple Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be importing an admission related dataset with 400 tuples. Attributes: gre, gpa, rank & admit(admission: 1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "X_data = data[['gre', 'gpa', 'rank']].values\n",
    "Y_data = data[['admit']].values\n",
    "X1_data = data[['gre']].values\n",
    "X2_data = data[['gpa']].values\n",
    "X3_data = data[['rank']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuples:  400\n"
     ]
    }
   ],
   "source": [
    "n_samples = Y_data.shape[0]\n",
    "print(\"Number of tuples: \", n_samples)\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "display_step = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X1 = tf.placeholder(\"float\")\n",
    "X2 = tf.placeholder(\"float\")\n",
    "X3 = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W1 = tf.Variable(rng.randn(), name=\"weight1\")\n",
    "W2 = tf.Variable(rng.randn(), name=\"weight2\")\n",
    "W3 = tf.Variable(rng.randn(), name=\"weight3\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "#Our Linear Model\n",
    "hypothesis = tf.add(tf.add(tf.multiply(X1, W1), tf.add(tf.multiply(X2, W2), tf.multiply(X3, W3))), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(hypothesis-Y, 2))/(2*n_samples)\n",
    "\n",
    "#Gradient descent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 cost= 0.000230257 W1= -0.00423923 W2= 1.4147941 W3= -0.9296645 b= 0.25817356\n",
      "Epoch: 0010 cost= 0.001191258 W1= -0.003508592 W2= 1.2216084 W3= -0.59912616 b= 0.12669756\n",
      "Epoch: 0015 cost= 0.000610307 W1= -0.004179738 W2= 0.80043983 W3= -0.35940206 b= -0.226408\n",
      "Epoch: 0020 cost= 0.000222063 W1= -0.0020125585 W2= 0.47838065 W3= -0.19691958 b= -0.48409256\n",
      "Epoch: 0025 cost= 0.000000007 W1= -0.00033257063 W2= 0.31011748 W3= -0.14973071 b= -0.55530447\n",
      "Optimization Finished!\n",
      "Training cost= 6.7162023e-09 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x1, x2, x3, y) in zip(X1_data, X2_data, X3_data, Y_data):\n",
    "            sess.run(optimizer, feed_dict={X1: x1, X2: x2, X3: x3, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X1: x1, X2: x2, X3: x3, Y: y})\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W1=\", sess.run(W1), \"W2=\", sess.run(W2),\"W3=\", sess.run(W3),\"b=\", sess.run(b))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X1: x1, X2: x2, X3: x3, Y: y})\n",
    "    print (\"Training cost=\", training_cost,'\\n')\n",
    "    \n",
    "    #Graph to be added\n",
    "    #Evaluation on test (after train_test_split) to be added\n",
    "    #Seems to overfit because the Cost is too damn low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
